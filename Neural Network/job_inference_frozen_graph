#!/bin/bash
#SBATCH -t 1:00:00
####SBATCH -t 1-00:00:00
####SBATCH -t 10:00:00
#SBATCH -N 1
#SBATCH -p short

cd ~/microhh/cases/moser600/git_repository/Neural\ Network/

#Load modules new environment
module purge
module load surf-devel
module load 2019
module load intel/2018b
module load netCDF/4.6.1-intel-2018b
module load netCDF-C++4/4.3.0-intel-2018b
module load CMake/3.12.1-GCCcore-7.3.0
module load cuDNN/7.6.3-CUDA-10.0.130
module load FFTW/3.3.8-intel-2018b
module load Doxygen/1.8.14-GCCcore-7.3.0

##Load modules old environment
#module purge
##module load eb
#module load surfsara
#module load CMake/3.7.2-intel-2016b
##module load cuDNN/7.0.5-CUDA-9.0.176
#module load netCDF/4.4.1.1-intel-2016b
#module load netCDF-C++4/4.3.0-intel-2016b
#module load FFTW/3.3.5-intel-2016b
#module load Doxygen/1.8.11-intel-2016b

export LD_LIBRARY_PATH=$SURFSARA_LIBRARY_PATH:$LD_LIBRARY_PATH #Make sure shared libraries can be found

source ~/virtualenv/firstCNN_intel_CPU/bin/activate

#Make frozen graph
#python3 optimize_for_inference.py --input /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP4/graph.pbtxt --output /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP4/optimized_graph.pbtxt --input_names concat --output_names Mul,save/restore_all --frozen_graph=False

#python3 freeze_graph.py --input_graph /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP4/optimized_graph.pbtxt --input_checkpoint /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP4/model.ckpt-500000 --output_graph /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP4/frozen_graph.pb --output_node_names Mul
#Get remark of new intialized thread pool with default settings for inter_op_parallelism_threads

#Do inference
python3 -u inference_MLP.py --frozen_graph_filename /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP13/frozen_inference_graph.pb --training_filename /projects/1/flowsim/simulation1/lesscoarse/training_data.nc --inference_filename /home/robinst/microhh/cases/moser600/git_repository/Neural\ Network/predictions_real_data_MLP13/inference_reconstructed_field_manual_python.nc --variables_filepath /home/robinst/microhh/cases/moser600/git_repository/CNN_checkpoints/real_data_MLP13/ --store_variables

#GO TO LISA WHEN USING TENSORRT FOR INFERENCE ON GPU, and execute commands below
#convert-to-uff convert-to-uff ~/inference_firstMLP/frozen_graph/MLP1.pb -o uff/MLP1.uff -O outputs/BiasAdd
#REMARKS BELOW ONLY FOR CNN:
#Get remark DEBUG: convert reshape to flatten node
#Get remark warning: No conversion function registered for layer: Conv3D yet. Converting conv1/Conv3D as custom op: Conv3D.
